<h1 align="center">
  Tech Challenge Marrow üöÄ
</h1>

<p align="center">
  <a href="#rocket-o-desafio">O desafio</a>&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;
  <a href="#hammer_and_wrench-decisoes-de-implementacao-e-metodologias-utilizadas">Ferramentas e Decis√µes</a>&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;  
  <a href="#memo-requisitos">Requisitos</a>&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;
  <a href="#rocket-tecnologias">Tecnologias</a>&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;
  <a href="#information_source-como-usar">Como usar</a>&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;
  <a href="#scroll-scripts-dispon√≠veis">Scripts dispon√≠veis</a>&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;
</p>

## :rocket: O desafio
O projeto "Desafio Marrow - IA" tem como objetivo desenvolver um sistema que detecta comportamentos inadequados em conversas de √°udio dentro de um espaco educacional, p√∫blico ou corporativo. Os principais requisitos incluem:
 - Implementa√ß√£o de um sistema de transcri√ß√£o de √°udio 
 - Realiza√ß√£o de an√°lise de sentimento e detec√ß√£o de linguagem t√≥xica
 - Cria√ß√£o de uma interface de usu√°rio

As tecnologias utilizadas para a implementa√ß√£o foram Python, Next.js, TailwindCSS e Docker. 

## :hammer_and_wrench: Decis√µes de Implementa√ß√£o e Metodologias Utilizadas

### 1. Transcri√ß√£o de √°udio
A transcri√ß√£o foi implementada utilizando a biblioteca [SpeechRecognition](https://github.com/Uberi/speech_recognition#readme) em Python, que oferece suporte a diversos modelos de convers√£o de fala para texto. Para este projeto, escolheu-se o modelo Whisper da [OpenAI](https://openai.com/whisper) devido √† sua acur√°cia e pelas op√ß√µes de executar localmente ou pela API. 

O Whisper Local foi adotado para garantir privacidade, uma vez que os dados s√£o processados localmente, sem a necessidade de envio para a nuvem. Essa abordagem tamb√©m permite controlar o consumo de recursos e ajustar a precis√£o conforme a capacidade computacional dispon√≠vel. 

Como alternativa, o Whisper API foi integrado para oferecer uma solu√ß√£o pr√°tica para casos em que recursos locais sejam limitados.

---

### 2. An√°lise de Sentimento e Detec√ß√£o de Linguagem T√≥xica
Inicialmente, foi utilizada a biblioteca [Transformers](https://github.com/huggingface/transformers), que oferece acesso a modelos pr√©-treinados do [Hugging Face](https://huggingface.co/). Embora testados diversos modelos, eles enfrentaram limita√ß√µes significativas em idiomas diferentes do ingl√™s, evidenciando tanto menor desempenho em detec√ß√µes de express√µes t√≥xicas e abusivas quanto classifica√ß√µes err√¥neas constantes.

Para superar essas limita√ß√µes, foi adotada a API da OpenAI (LLM), que demonstrou:
- Alta precis√£o na classifica√ß√£o de emo√ß√µes e na detec√ß√£o de linguagem t√≥xica, mesmo em express√µes mais sutis.
- Suporte a m√∫ltiplos idiomas, garantindo uma experi√™ncia consistente em qualquer contexto.
- Utilizando *structured outputs*, que assegura consist√™ncia nas respostas do modelo e no formato de exibi√ß√£o para o usu√°rio

A an√°lise de linguagem t√≥xica foi organizada em 8 categorias, baseando-se no esquema do [Perspective API](https://perspectiveapi.com/), um projeto que visa identificar e categorizar coment√°rios t√≥xicos e abusivos. As categorias s√£o:
- TOXICITY: Coment√°rios rudes, desrespeitosos ou irracionais.
- IDENTITY_ATTACK: Coment√°rios negativos ou odiosos que atacam algu√©m por causa de sua identidade.
- INSULT: Coment√°rios insultuosos, inflamados ou negativos direcionados a uma pessoa ou grupo.
- ROFANITY: Uso de palavr√µes, xingamentos ou linguagem obscena.
- THREAT: Descri√ß√µes de inten√ß√µes de infligir dor, ferimentos ou viol√™ncia contra um indiv√≠duo ou grupo.
- SEXUALLY_EXPLICIT: Refer√™ncias a atos sexuais, partes do corpo ou outros conte√∫dos lascivos.
- FLIRTATION: Cantadas, elogios √† apar√™ncia ou insinua√ß√µes sexuais sutis.
- OTHER: Coment√°rios t√≥xicos ou abusivos que n√£o se enquadram nas categorias anteriores.

Essa categoriza√ß√£o detalhada permite maior precis√£o na an√°lise e oferece uma bom meio para detectar comportamentos inadequados.

Os dois modelos ‚Äî Transformers e LLM ‚Äî permanecem dispon√≠veis para uso. Contudo, recomenda-se fortemente o uso da LLM devido √† sua superioridade em performance. Ainda assim, algumas considera√ß√µes importantes devem ser feitas:

1. Transformers: Apesar da menor precis√£o observada em alguns cen√°rios, existe a possibilidade de realizar um fine-tuning nos modelos, o que poderia melhorar significativamente a acur√°cia para o problema em quest√£o sem a necessidade de utilizar um modelo computacionalmente pesado. No entanto, essa abordagem n√£o foi explorada neste projeto devido √† falta de dados, tempo e recursos computacionais necess√°rios para tal treinamento.

2. Alternativas √† LLM: Atualmente, a implementa√ß√£o utiliza a API da OpenAI, mas existem outras op√ß√µes vi√°veis, como o LLaMA, que tamb√©m suporta structured outputs. Isso abriria a possibilidade de executar o modelo localmente, preservando dados sens√≠veis, al√©m de permitir fine-tuning, oferecendo flexibilidade para cen√°rios futuros.

---

### 3. Formata√ß√£o de Texto e Identifica√ß√£o de Falantes
Durante os testes, observou-se que as transcri√ß√µes brutas eram de dif√≠cil leitura devido √† falta de formata√ß√£o. Para solucionar esse problema, foi implementada uma funcionalidade de formata√ß√£o autom√°tica, utilizando a API da OpenAI.

A formata√ß√£o reorganiza o conte√∫do em par√°grafos claros e estruturados, al√©m de identificar os falantes (por exemplo, "Professor" e "Aluno"), melhorando significativamente a legibilidade e usabilidade do texto.

Ambas vers√µes das transcri√ß√µes ‚Äî formatadas e n√£o formatadas ‚Äî s√£o armazenadas no sistema e podem ser baixadas pelo usu√°rio.

### 4. Sumariza√ß√£o do texto
Como se trata de um sistema de monitoramento para um ambiente educacional, surgiu a ideia de implementar uma funcionalidade de sumariza√ß√£o do texto transcrito para verificar se o professor est√° se mantendo dentro do t√≥pico da aula. Para isso, novamente utilizou-se modelos baseados na arquitetura Transformer, especialmente voltados para a tarefa de sumariza√ß√£o.

Atualmente, o sistema oferece suporte para sumariza√ß√£o em dois idiomas: ingl√™s e portugu√™s. No entanto, o desempenho dos modelos √© significativamente melhor em ingl√™s, devido ao tamanho do modelo utilizado [facebook/bart-large-cnn](https://huggingface.co/facebook/bart-large-cnn), o que confere ao modelo uma maior acur√°cia e relev√¢ncia nas informa√ß√µes extra√≠das.

Por√©m, o portugu√™s foi integrado principalmente como *proof of concept*, utilizando o modelo [phpaiola/ptt5-base-summ-xlsum](https://huggingface.co/recogna-nlp/ptt5-base-summ-xlsum), demonstrando que a tarefa de sumariza√ß√£o √© vi√°vel tamb√©m para o idioma. Embora o desempenho do modelo em portugu√™s ainda seja inferior, a cria√ß√£o de modelos maiores e mais robustos poderia melhorar consideravelmente os resultados dessa funcionalidade. Essa implementa√ß√£o no portugu√™s serve como um indicativo de que, com o treinamento adequado, o modelo poderia garantir maior precis√£o na sumariza√ß√£o de conte√∫dos.

---

## :memo: Requisitos

| Ferramenta| Vers√£o  | Descri√ß√£o                                    |
|-----------|---------|----------------------------------------------|
| [Docker](https://www.docker.com/)              | 27.3.1 | Plataforma de cont√™ineres que permite empacotar, distribuir e executar o aplicativo de forma isolada, garantindo consist√™ncia no ambiente de desenvolvimento e produ√ß√£o.  |
| [Git](https://git-scm.com/)           | | |

## :man_technologist: Tecnologias

Este projeto est√° sendo desenvolvido com as seguintes tecnologias:

-  Linguagens: [Typescript](https://www.typescriptlang.org/) e [Python](https://www.python.org/);
-  Estiliza√ß√£o: [Tailwind](https://tailwindcss.com/) 
-  Front-end: [ReactJS](https://reactjs.org/) e [Next.js](https://nextjs.org/);
-  Back-end: [Flask](https://flask.palletsprojects.com/en/stable/)
-  Cont√™iner: [Docker](https://www.docker.com/)

## :information_source: Como usar

Um tutorial em v√≠deo est√° dispon√≠vel neste [link](https://youtu.be/).

```bash
# Clonar este reposit√≥rio
$ git clone https://github.com/Zephrysz/Marrow-Challenge.git
# Ir para o reposit√≥rio
$ cd Marrow-Challenge
# Rodar a aplica√ß√£o em ambiente de desenvolvimento
$ docker compose up
```

## :scroll: Scripts dispon√≠veis

- `docker compose up`: Inicia os containers da aplica√ß√£o
- `docker compose down`: Para e remove todos os cont√™iners, redes e volumes associado ao projeto
- `docker compose up --build`: Flag que for√ßa a reconstru√ß√£o das imagens Docker antes de iniciar os containers. Use quando houver mudan√ßas nos arquivos de configura√ß√£o ou c√≥digo.
- `docker compose up --watch`: Habilita o modo de observa√ß√£o, que reinicia automaticamente a aplica√ß√£o ao detectar altera√ß√µes nos arquivos de c√≥digo


Ap√≥s rodar o comando, a aplica√ß√£o estar√° dispon√≠vel em: [localhost:3000](http://localhost:3000/)

